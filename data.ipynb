{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1362a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "import nibabel as nib\n",
    "import os \n",
    "import glob\n",
    "import  matplotlib.pyplot as plt\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = '/home/arisa/Documents/qazal/case'\n",
    "sli_path = '/home/arisa/Documents/qazal/slice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f84f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_box(mask):\n",
    "    '''\n",
    "    this function return dict object contain bounding box of each pixel label and bbox of true value in bolean array\n",
    "    '''\n",
    "    box = []\n",
    "    box_bool=[]\n",
    "    obj_ids = np.unique(mask)\n",
    "    if mask.dtype == bool:\n",
    "        if len(np.unique(mask))==2:\n",
    "            \n",
    "            y_min = np.nonzero(mask)[0].min()\n",
    "            y_max = np.nonzero(mask)[0].max()\n",
    "            x_min = np.nonzero(mask)[1].min()\n",
    "            x_max = np.nonzero(mask)[1].max()\n",
    "            box=[x_min, y_min, x_max, y_max]\n",
    "    else :\n",
    "        mask_bool = mask.astype(np.bool)\n",
    "        if len(np.unique(mask_bool))==2:\n",
    "            \n",
    "            y_min = np.nonzero(mask_bool)[0].min()\n",
    "            y_max = np.nonzero(mask_bool)[0].max()\n",
    "            x_min = np.nonzero(mask_bool)[1].min()\n",
    "            x_max = np.nonzero(mask_bool)[1].max()\n",
    "            box_bool=[x_min, y_min, x_max, y_max]\n",
    "        \n",
    "        for i in  obj_ids[1:]:\n",
    "            y_min = np.nonzero(mask==i)[0].min()\n",
    "            y_max = np.nonzero(mask==i)[0].max()\n",
    "            x_min = np.nonzero(mask==i)[1].min()\n",
    "            x_max = np.nonzero(mask==i)[1].max()\n",
    "            box.append([x_min, y_min, x_max, y_max])\n",
    "    return_object = {'bbox_bool': box} if mask.dtype ==bool else {'bbox_label': dict(zip([f\"label{int(i)}\" for i in obj_ids[1:]],box)), 'bbox_bool' : box_bool}\n",
    "    return return_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_label(masks):\n",
    "\n",
    "    l0 = []\n",
    "    l1_0 =[]\n",
    "    l2_0 = []\n",
    "    l2_1_0 = []\n",
    "    for i in range(masks.shape[-1]):\n",
    "        uni = np.unique(masks[:,:,i])\n",
    "\n",
    "        if len(uni) ==1:\n",
    "            l0.append(i)\n",
    "        elif (0 in uni) and (1 in uni) and not (2 in uni):\n",
    "            l1_0.append(i)\n",
    "        elif (0 in uni) and (2 in uni) and not (1 in uni):\n",
    "            l2_0.append(i)\n",
    "        else :\n",
    "            l2_1_0.append(i)\n",
    "    \n",
    "    return {'label_0':l0, 'label_1_0':l1_0,'label_2_0': l2_0, 'label_2_1_0': l2_1_0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_channel(image, dim_channel = 2):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        mean = torch.mean(image, dim_channel, keepdims=True)\n",
    "        std = torch.std(image, dim_channel, keepdims=True)\n",
    "        normal = (image-mean)/std\n",
    "    \n",
    "    else :\n",
    "        mean = np.mean(image, dim_channel, keepdims=True)\n",
    "        std = np.std(image, dim_channel, keepdims=True)\n",
    "        normal = (image-mean)/std\n",
    "    \n",
    "    return normal\n",
    "\n",
    "def normalization(image):\n",
    "    \n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        normal = (image-mean)/std\n",
    "    \n",
    "        return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_specific(im, mask, crop_size):\n",
    "        \n",
    "        k=make_box(mask.astype(np.bool))\n",
    "        if len(k['bbox_bool'])!=0:\n",
    "            b_list = k['bbox_bool']\n",
    "            x_min, y_min, x_max, y_max = b_list\n",
    "            \n",
    "            length_x = x_max -x_min + 1\n",
    "            length_y = y_max - y_min + 1\n",
    "            del_x = crop_size - length_x \n",
    "            del_y = crop_size - length_y \n",
    "\n",
    "            if del_x%2==0:\n",
    "                kx = del_x//2\n",
    "                sx=0\n",
    "            else:\n",
    "                kx = del_x//2\n",
    "\n",
    "                sx = 1\n",
    "            if del_y%2==0:\n",
    "                ky = del_y//2\n",
    "                sy=0\n",
    "            else:\n",
    "                ky = del_y//2\n",
    "                sy = 1\n",
    "            \n",
    "            crop = mask[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
    "            crop_im = im[ y_min - ky - sy : y_max + ky + 1, x_min - kx - sx : x_max + kx  + 1]\n",
    "            return crop_im, crop,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ceee9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5586ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class promise(torch.utils.data.Dataset):\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self,slice_root, crop=192, mode = 'train', booli = True, test_size = 0.3):\n",
    "        super().__init__()\n",
    "        self.bool = booli\n",
    "        self.crop = crop\n",
    "        self.image = glob.glob(slice_root + '/*HK*Case[0-9][0-9]_[0-9]*') +glob.glob(slice_root + '/*BIDMC*Case[0-9][0-9]_[0-9]*')+glob.glob(slice_root + '/*UCL*Case[0-9][0-9]_[0-9]*')# all image\n",
    "        self.segment = glob.glob(slice_root + '/*HK*[sS]eg*') +glob.glob(slice_root + '/*BIDMC*[sS]eg*')+glob.glob(slice_root + '/*UCL*[sS]eg*')\n",
    "        self.image.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        self.segment.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        \n",
    "        im_train = []\n",
    "        seg_train = []\n",
    "\n",
    "        im_test = []\n",
    "        seg_test = []\n",
    "\n",
    "        im_val = []\n",
    "        seg_val = []\n",
    "        for en, i in enumerate(os.walk(case)):\n",
    "            if en>0 and (os.path.basename(i[0])=='BIDMC' or os.path.basename(i[0])=='HK' or\n",
    "                        os.path.basename(i[0])=='UCL') :\n",
    "                patients_list = glob.glob(i[0] + '/' + '*[0-9].*')\n",
    "                patients_list.sort()\n",
    "                segment_list = glob.glob(i[0] + '/' + '*n.*')\n",
    "                segment_list.sort()\n",
    "                test_val_len = math.ceil(test_size * len(patients_list))\n",
    "               \n",
    "            \n",
    "                random.seed(23)\n",
    "                image_case_val_test = random.sample(patients_list, k = test_val_len)\n",
    "                random.seed(23)\n",
    "                segment_case_val_test = random.sample(segment_list, k = test_val_len)\n",
    "        \n",
    "        \n",
    "                image_case_train = list(set(patients_list) - set(image_case_val_test))\n",
    "                segment_case_train = list(set(segment_list) - set(segment_case_val_test))\n",
    "        \n",
    "    \n",
    "                test_len = math.ceil(0.7 * len(image_case_val_test))\n",
    "                random.seed(23)\n",
    "                image_case_test = random.sample(image_case_val_test, k = test_len)\n",
    "                random.seed(23)\n",
    "                segment_case_test = random.sample(segment_case_val_test, k = test_len)\n",
    "        \n",
    "        \n",
    "                image_case_val = list(set(image_case_val_test) - set(image_case_test))\n",
    "                segment_case_val = list(set(segment_case_val_test) - set(segment_case_test))\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "                folder = os.path.basename(i[0])\n",
    "\n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_train]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_train]\n",
    "\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "                im_train.extend(bas)\n",
    "                seg_train.extend(bas1)\n",
    "        \n",
    "        \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_test]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_test]\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "                im_test.extend(bas)\n",
    "                seg_test.extend(bas1)\n",
    "        \n",
    "        \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_val]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_val]\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "\n",
    "                im_val.extend(bas)\n",
    "                seg_val.extend(bas1)\n",
    "        \n",
    "        \n",
    "        image_slice_train = []\n",
    "        segment_slice_train= []\n",
    "        for im, seg in zip(im_train, seg_train):\n",
    "            image_slice_train.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_train.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        image_slice_test = []\n",
    "        segment_slice_test = []\n",
    "        for im, seg in zip(im_test, seg_test):\n",
    "            image_slice_test.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_test.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        image_slice_val = []\n",
    "        segment_slice_val = []\n",
    "        for im, seg in zip(im_val, seg_val):\n",
    "            image_slice_val.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_val.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        image_slice_train.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_train.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))        \n",
    "           \n",
    "        image_slice_test.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_test.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))           \n",
    "        image_slice_val.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_val.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))        \n",
    "        \n",
    "        if mode =='train':\n",
    "            self.general_im = image_slice_train\n",
    "            self.general_seg = segment_slice_train\n",
    "        elif mode == 'test':\n",
    "            self.general_im = image_slice_test\n",
    "            self.general_seg = segment_slice_test\n",
    "        elif mode=='val':\n",
    "            self.general_im = image_slice_val\n",
    "            self.general_seg = segment_slice_val    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.general_im) \n",
    "    def __getitem__(self, val):\n",
    "        crop =self.crop\n",
    "        image_array = np.load(self.general_im[val])\n",
    "        segment_array = np.load(self.general_seg[val])\n",
    "        k=make_box(segment_array.astype(np.bool))\n",
    "        if len(k['bbox_bool'])!=0:\n",
    "        \n",
    "             im_c , seg_c = crop_specific(image_array, segment_array, crop)\n",
    "        else :\n",
    "            im_c , seg_c = resize(image_array, (crop,crop)), resize(segment_array, (crop,crop))\n",
    "        image_array_normal = normalization(im_c)\n",
    "        \n",
    "        if self.bool:\n",
    "            seg_c[seg_c>=1.0]=1.0\n",
    "        org_dim_image = np.expand_dims(image_array_normal, 0)\n",
    "        org_dim_seg = np.expand_dims(seg_c, 0)\n",
    "        org_dim_image = np.float32(org_dim_image)\n",
    "        org_dim_seg = np.float32(org_dim_seg)\n",
    "\n",
    "        \n",
    "        \n",
    "        return {'image':org_dim_image, 'seg':org_dim_seg}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISBIDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self,slice_root, crop=192, mode = 'train', booli = True, test_size = 0.2):\n",
    "        super().__init__()\n",
    "        self.bool = booli\n",
    "        self.crop = crop\n",
    "        self.image = glob.glob(slice_root + '/*ISBI*Case[0-9][0-9]_[0-9]*') # all image\n",
    "        self.segment = glob.glob(slice_root + '/*ISBI*[sS]eg*')\n",
    "        self.image.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        self.segment.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        \n",
    "        im_train = []\n",
    "        seg_train = []\n",
    "\n",
    "        im_test = []\n",
    "        seg_test = []\n",
    "\n",
    "        im_val = []\n",
    "        seg_val = []\n",
    "        for en, i in enumerate(os.walk(case)):\n",
    "            if en>0 and (os.path.basename(i[0])=='ISBI' or os.path.basename(i[0])=='ISBI-1.5') :\n",
    "                patients_list = glob.glob(i[0] + '/' + '*[0-9].*')\n",
    "                patients_list.sort()\n",
    "                segment_list = glob.glob(i[0] + '/' + '*n.*')\n",
    "                segment_list.sort()\n",
    "                test_val_len = math.ceil(test_size * len(patients_list))\n",
    "               \n",
    "            \n",
    "                random.seed(23)\n",
    "                image_case_val_test = random.sample(patients_list, k = test_val_len)\n",
    "                random.seed(23)\n",
    "                segment_case_val_test = random.sample(segment_list, k = test_val_len)\n",
    "        \n",
    "        \n",
    "                image_case_train = list(set(patients_list) - set(image_case_val_test))\n",
    "                segment_case_train = list(set(segment_list) - set(segment_case_val_test))\n",
    "        \n",
    "    \n",
    "                test_len = math.ceil(0.6 * len(image_case_val_test))\n",
    "                random.seed(23)\n",
    "                image_case_test = random.sample(image_case_val_test, k = test_len)\n",
    "                random.seed(23)\n",
    "                segment_case_test = random.sample(segment_case_val_test, k = test_len)\n",
    "        \n",
    "        \n",
    "                image_case_val = list(set(image_case_val_test) - set(image_case_test))\n",
    "                segment_case_val = list(set(segment_case_val_test) - set(segment_case_test))\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "                folder = os.path.basename(i[0])\n",
    "\n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_train]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_train]\n",
    "\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "                im_train.extend(bas)\n",
    "                seg_train.extend(bas1)\n",
    "        \n",
    "        \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_test]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_test]\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "                im_test.extend(bas)\n",
    "                seg_test.extend(bas1)\n",
    "        \n",
    "        \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_val]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_val]\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "\n",
    "                im_val.extend(bas)\n",
    "                seg_val.extend(bas1)\n",
    "        \n",
    "        \n",
    "        image_slice_train = []\n",
    "        segment_slice_train= []\n",
    "        for im, seg in zip(im_train, seg_train):\n",
    "            image_slice_train.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_train.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        image_slice_test = []\n",
    "        segment_slice_test = []\n",
    "        for im, seg in zip(im_test, seg_test):\n",
    "            image_slice_test.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_test.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        image_slice_val = []\n",
    "        segment_slice_val = []\n",
    "        for im, seg in zip(im_val, seg_val):\n",
    "            image_slice_val.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            segment_slice_val.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        image_slice_train.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_train.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))        \n",
    "           \n",
    "        image_slice_test.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_test.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))           \n",
    "        image_slice_val.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        segment_slice_val.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))        \n",
    "        \n",
    "        if mode =='train':\n",
    "            self.general_im = image_slice_train\n",
    "            self.general_seg = segment_slice_train\n",
    "        elif mode == 'test':\n",
    "            self.general_im = image_slice_test\n",
    "            self.general_seg = segment_slice_test\n",
    "        elif mode=='val':\n",
    "            self.general_im = image_slice_val\n",
    "            self.general_seg = segment_slice_val    \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.general_im) \n",
    "    def __getitem__(self, val):\n",
    "        crop =self.crop\n",
    "        image_array = np.load(self.general_im[val])\n",
    "        segment_array = np.load(self.general_seg[val])\n",
    "        k=make_box(segment_array.astype(np.bool))\n",
    "        if len(k['bbox_bool'])!=0:\n",
    "        \n",
    "             im_c , seg_c = crop_specific(image_array, segment_array, crop)\n",
    "        else :\n",
    "            im_c , seg_c = resize(image_array, (crop,crop)), resize(segment_array, (crop,crop))\n",
    "        image_array_normal = normalization(im_c)\n",
    "        \n",
    "        if self.bool:\n",
    "            seg_c[seg_c>=1.0]=1.0\n",
    "        org_dim_image = np.expand_dims(image_array_normal, 0)\n",
    "        org_dim_seg = np.expand_dims(seg_c, 0)\n",
    "        org_dim_image = np.float32(org_dim_image)\n",
    "        org_dim_seg = np.float32(org_dim_seg)\n",
    "\n",
    "        \n",
    "        \n",
    "        return {'image':org_dim_image, 'seg':org_dim_seg}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class i2cv(torch.utils.data.Dataset):\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self,slice_root, crop=192, mode = 'train', booli = True):\n",
    "        super().__init__()\n",
    "        self.bool = booli\n",
    "        self.crop = crop\n",
    "        self.image = glob.glob(slice_root + '/*I2CVB*Case[0-9][0-9]_[0-9]*') # all image\n",
    "        self.segment = glob.glob(slice_root + '/*I2CVB*[sS]eg*')\n",
    "        self.image.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        self.segment.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        \n",
    "        j_i = []\n",
    "        s_i = []\n",
    "        # this for loop select randomly test data and append in 2 list(test data is case id)\n",
    "        for en, i in enumerate(os.walk(case)):\n",
    "            if en>0 and (os.path.basename(i[0])=='I2CVB') :\n",
    "                patients_list = glob.glob(i[0] + '/' + '*[0-9].*')\n",
    "                patients_list.sort()\n",
    "                segment_list = glob.glob(i[0] + '/' + '*n.*')\n",
    "                segment_list.sort()\n",
    "                test_len = int(0.2 * len(patients_list))\n",
    "                #im_val = patients_list[:val_len]\n",
    "                #seg_val = segment_list[:val_len]\n",
    "            \n",
    "                random.seed(23)\n",
    "                image_case_test = random.sample(patients_list, k = test_len)\n",
    "                random.seed(23)\n",
    "                segment_case_test = random.sample(segment_list, k = test_len)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_test]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_test]\n",
    "\n",
    "                folder = os.path.basename(i[0])\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "\n",
    "                j_i.extend(bas)\n",
    "                s_i.extend(bas1)\n",
    "        self.image_slice_test = []\n",
    "        self.segment_slice_test = []\n",
    "        for im, seg in zip(j_i, s_i):\n",
    "            self.image_slice_test.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            self.segment_slice_test.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        self.image_slice_test.sort()\n",
    "        self.segment_slice_test.sort()\n",
    "        \n",
    "        self.train_im = list(set(self.image) - set(self.image_slice_test))\n",
    "        self.train_im.sort()\n",
    "        \n",
    "        self.train_seg = list(set(self.segment) - set(self.segment_slice_test))\n",
    "        self.train_seg.sort()\n",
    "                \n",
    "        if mode =='train':\n",
    "            self.general_im = self.train_im\n",
    "            self.general_seg = self.train_seg\n",
    "        elif mode == 'test':\n",
    "            self.general_im = self.image_slice_test\n",
    "            self.general_seg = self.segment_slice_test            \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.general_im) \n",
    "    def __getitem__(self, val):\n",
    "        crop =self.crop\n",
    "        image_array = np.load(self.general_im[val])\n",
    "        segment_array = np.load(self.general_seg[val])\n",
    "        k=make_box(segment_array.astype(np.bool))\n",
    "        if len(k['bbox_bool'])!=0:\n",
    "        \n",
    "             im_c , seg_c = crop_specific(image_array, segment_array, crop)\n",
    "        else :\n",
    "            im_c , seg_c = resize(image_array, (crop,crop)), resize(segment_array, (crop,crop))\n",
    "        image_array_normal = normalization(im_c)\n",
    "        \n",
    "        if self.bool:\n",
    "            seg_c[seg_c>=1.0]=1.0\n",
    "        org_dim_image = np.expand_dims(image_array_normal, 0)\n",
    "        org_dim_seg = np.expand_dims(seg_c, 0)\n",
    "        org_dim_image = np.float32(org_dim_image)\n",
    "        org_dim_seg = np.float32(org_dim_seg)\n",
    "\n",
    "        \n",
    "        \n",
    "        return {'image':org_dim_image, 'seg':org_dim_seg}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dat(torch.utils.data.Dataset):\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self,slice_root, crop=192, mode = 'train', booli = True):\n",
    "        super().__init__()\n",
    "        self.bool = booli\n",
    "        self.crop = crop\n",
    "        self.image = glob.glob(slice_root + '/*Case[0-9][0-9]_[0-9]*') # all image\n",
    "        self.segment = glob.glob(slice_root + '/*[sS]eg*')\n",
    "        self.image.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        self.segment.sort(key = lambda x : int(x.split('.')[-2].split('_')[-1]))\n",
    "        \n",
    "        j_i = []\n",
    "        s_i = []\n",
    "        # this for loop select randomly test data and append in 2 list(test data is case id)\n",
    "        for en, i in enumerate(os.walk(case)):\n",
    "            if en>0 :\n",
    "                patients_list = glob.glob(i[0] + '/' + '*[0-9].*')\n",
    "                patients_list.sort()\n",
    "                segment_list = glob.glob(i[0] + '/' + '*n.*')\n",
    "                segment_list.sort()\n",
    "                test_len = int(0.2 * len(patients_list))\n",
    "                #im_val = patients_list[:val_len]\n",
    "                #seg_val = segment_list[:val_len]\n",
    "            \n",
    "                random.seed(23)\n",
    "                image_case_test = random.sample(patients_list, k = test_len)\n",
    "                random.seed(23)\n",
    "                segment_case_test = random.sample(segment_list, k = test_len)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "                file_name = [f.split('/')[-1].split('.')[0] for f in image_case_test]\n",
    "                file_name_s = [f.split('/')[-1].split('.')[0] for f in segment_case_test]\n",
    "\n",
    "                folder = os.path.basename(i[0])\n",
    "                bas = [folder + '_' + i for i in  file_name]\n",
    "                bas1 = [folder + '_' + i for i in  file_name_s]\n",
    "\n",
    "                j_i.extend(bas)\n",
    "                s_i.extend(bas1)\n",
    "        self.image_slice_test = []\n",
    "        self.segment_slice_test = []\n",
    "        for im, seg in zip(j_i, s_i):\n",
    "            self.image_slice_test.extend(glob.glob(sli_path + '/' + '*{}_[0-9]*'.format(im)))\n",
    "            self.segment_slice_test.extend(glob.glob(sli_path + '/' + '*{}*'.format(seg)))\n",
    "            \n",
    "        self.image_slice_test.sort()\n",
    "        self.segment_slice_test.sort()\n",
    "        \n",
    "        self.train_im = list(set(self.image) - set(self.image_slice_test))\n",
    "        self.train_im.sort()\n",
    "        \n",
    "        self.train_seg = list(set(self.segment) - set(self.segment_slice_test))\n",
    "        self.train_seg.sort()\n",
    "                \n",
    "        if mode =='train':\n",
    "            self.general_im = self.train_im\n",
    "            self.general_seg = self.train_seg\n",
    "        elif mode == 'test':\n",
    "            self.general_im = self.image_slice_test\n",
    "            self.general_seg = self.segment_slice_test            \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.general_im) \n",
    "    def __getitem__(self, val):\n",
    "        crop =self.crop\n",
    "        image_array = np.load(self.general_im[val])\n",
    "        segment_array = np.load(self.general_seg[val])\n",
    "        k=make_box(segment_array.astype(np.bool))\n",
    "        if len(k['bbox_bool'])!=0:\n",
    "        \n",
    "             im_c , seg_c = crop_specific(image_array, segment_array, crop)\n",
    "        else :\n",
    "            im_c , seg_c = resize(image_array, (crop,crop)), resize(segment_array, (crop,crop))\n",
    "        image_array_normal = normalization(im_c)\n",
    "        if self.bool:\n",
    "            \n",
    "            seg_c[seg_c>=1.0]=1.0\n",
    "\n",
    "        \n",
    "        org_dim_image = np.expand_dims(image_array_normal, 0)\n",
    "        org_dim_seg = np.expand_dims(seg_c, 0)\n",
    "        org_dim_image = np.float32(org_dim_image)\n",
    "        org_dim_seg = np.float32(org_dim_seg)\n",
    "\n",
    "        \n",
    "        \n",
    "        return {'image':org_dim_image, 'seg':org_dim_seg}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7086da8",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51ed84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_activation, intermediate, expand = 1, stride = 1, down = None):\n",
    "        super().__init__()\n",
    "        self.expand = expand\n",
    "        output = intermediate * self.expand\n",
    "        self.conv1x1_1 = nn.Conv2d(input_activation, intermediate, 1)\n",
    "        self.BN1 = nn.BatchNorm2d(intermediate)\n",
    "        \n",
    "        self.conv3x3 =  nn.Conv2d(intermediate, intermediate, 3, stride=stride, padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(intermediate)\n",
    "\n",
    "        self.conv1x1_2 =  nn.Conv2d(intermediate, output, 1)\n",
    "        self.BN3 = nn.BatchNorm2d(output)\n",
    "       \n",
    "        self.down = nn.Conv2d(input_activation, output, 1, stride=stride)\n",
    "        \n",
    "    def forward(self , inp):\n",
    "        inp1 = inp\n",
    "        c = F.relu(self.BN1(self.conv1x1_1(inp)))\n",
    "        c = F.relu(self.BN2(self.conv3x3(c)))\n",
    "        c = F.relu(self.BN3(self.conv1x1_2(c)))\n",
    "        if self.down!=None:\n",
    "            inp1 = self.down(inp)\n",
    "        \n",
    "        out = F.relu(c + inp1) \n",
    "        out=  F.dropout2d(out, p=0.2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8812b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_activation, intermediate, expand = 1, stride = 1, p = 0.1):\n",
    "        super().__init__()\n",
    "     \n",
    "        self.p = p\n",
    "        self.conv3x3 =  nn.Conv2d(input_activation, intermediate, 3, stride=stride, padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(intermediate)\n",
    "        \n",
    "        \n",
    "        self.conv3x3_1 =  nn.Conv2d(intermediate, intermediate, 3, stride=stride, padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(intermediate)\n",
    "\n",
    "        \n",
    "    def forward(self , inp):\n",
    "        c = F.relu(self.BN1(self.conv3x3(inp)))\n",
    "        c = F.relu(self.BN2(self.conv3x3_1(c)))\n",
    "   \n",
    "        \n",
    "       \n",
    "        out=  F.dropout2d(c, p = self.p)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0e3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_class):\n",
    "\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.inp = nn.Conv2d(1,16,3,padding=1)\n",
    "        self.en_block1 = block(16,32)\n",
    "        self.en_block2 = block(32,64)\n",
    "        self.en_block3 = block(64,128)\n",
    "        self.en_block4 = block(128,256)\n",
    "        self.en_block5 = block(256,512)\n",
    "        self.en_block6 = block(512, 1024)\n",
    "\n",
    "        \n",
    "        self.transpose5 = nn.ConvTranspose2d(1024,512,2,2)\n",
    "        self.transpose4 = nn.ConvTranspose2d(512,256,2,2)\n",
    "\n",
    "        self.transpose3 = nn.ConvTranspose2d(256,128,2,2)\n",
    "        self.transpose2 = nn.ConvTranspose2d(128,64,2,2)\n",
    "        self.transpose1 = nn.ConvTranspose2d(64,32,2,2)\n",
    "        \n",
    "        self.de_block1 = block(64,32)\n",
    "        self.de_block2 = block(128,64)\n",
    "        self.de_block3 = block(256,128)\n",
    "\n",
    "        self.de_block4 = block(512, 256)\n",
    "        self.de_block5 = block(1024, 512)\n",
    "        self.out_conv = nn.Conv2d(32, n_class, 1)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp  = self.inp(inp)\n",
    "        el1 = self.en_block1(inp) #  (32,h,w)\n",
    "        max1 = nn.MaxPool2d(2)(el1) # (32,h//2, w//2)\n",
    "\n",
    "        el2 = self.en_block2(max1)    #(64, h//2, w//2)\n",
    "\n",
    "        max2 = nn.MaxPool2d(2)(el2)  #(64, h//4, w//4)\n",
    "\n",
    "        el3 = self.en_block3(max2)    #(128, h//4, w//4)\n",
    "\n",
    "        max3 = nn.MaxPool2d(2)(el3)  #(128, h//8, w//8)\n",
    "\n",
    "\n",
    "        el4 = self.en_block4(max3)    #(256, h//8, w//8)\n",
    "\n",
    "        max4 = nn.MaxPool2d(2)(el4)  #(256, h//16, w//16)\n",
    "\n",
    "        el5 = self.en_block5(max4)  #(512, h//16, w//16)\n",
    "\n",
    "        max5 = nn.MaxPool2d(2)(el5)  #(512, h//32, w//32)\n",
    "\n",
    "        \n",
    "        el6 = self.en_block6(max5)  #(1024, h//32, w//32)\n",
    "\n",
    "\n",
    "        tl5 = self.transpose5(el6)  #(512, h//16, w//16)\n",
    "\n",
    "        cat5 = torch.cat([tl5, el5], 1) #(1024, h//16, h//16 )\n",
    "\n",
    "        d5 =  self.de_block5(cat5)      #(512, h//16, w//16\n",
    "\n",
    "        \n",
    "        tl4 = self.transpose4(d5)       #(256, h//8, w//8)\n",
    "        cat4 = torch.cat([tl4, el4], 1) #(512, h//8, w//8)\n",
    "        d4 =  self.de_block4(cat4)     #(256, h//8, w//8)\n",
    "        \n",
    "        tl3 = self.transpose3(d4)        #(128, h//4, w//4)\n",
    "        cat3 = torch.cat([tl3, el3], 1)  #(256, h//4, w//4)\n",
    "        d3 =  self.de_block3(cat3)        #(128, h//4, w//4)\n",
    "        \n",
    "        \n",
    "        tl2 = self.transpose2(d3)          #(64, h//2, w//2)\n",
    "        cat2 = torch.cat([tl2, el2], 1)   #(128, h//2, w//2)\n",
    "        d2 =  self.de_block2(cat2)         #(64, h//2, w//2)\n",
    "        \n",
    "        tl1 = self.transpose1(d2)          #(32, h, w)\n",
    "        cat1 = torch.cat([tl1, el1], 1) #(64, h, w)\n",
    "        d1 =  self.de_block1(cat1)        #(32, h, w)\n",
    "        output = torch.sigmoid(self.out_conv(d1)) \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a94b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_resnet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_class):\n",
    "\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        self.inp = nn.Conv2d(1,16,3,padding=1)\n",
    "        self.en_block1 = resnet_block(16,32)\n",
    "        self.en_block2 = resnet_block(32,64)\n",
    "        self.en_block3 = resnet_block(64,128)\n",
    "        self.en_block4 = resnet_block(128,256)\n",
    "        self.en_block5 = resnet_block(256,512)\n",
    "        self.en_block6 = resnet_block(512, 1024)\n",
    "\n",
    "        \n",
    "        self.transpose5 = nn.ConvTranspose2d(1024,512,2,2)\n",
    "        self.transpose4 = nn.ConvTranspose2d(512,256,2,2)\n",
    "\n",
    "        self.transpose3 = nn.ConvTranspose2d(256,128,2,2)\n",
    "        self.transpose2 = nn.ConvTranspose2d(128,64,2,2)\n",
    "        self.transpose1 = nn.ConvTranspose2d(64,32,2,2)\n",
    "        \n",
    "        self.de_block1 = resnet_block(64,32)\n",
    "        self.de_block2 = resnet_block(128,64)\n",
    "        self.de_block3 = resnet_block(256,128)\n",
    "\n",
    "        self.de_block4 = resnet_block(512, 256)\n",
    "        self.de_block5 = resnet_block(1024, 512)\n",
    "        self.out_conv = nn.Conv2d(32, n_class, 1)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp  = self.inp(inp)\n",
    "        el1 = self.en_block1(inp) #  (32,h,w)\n",
    "        max1 = nn.MaxPool2d(2)(el1) # (32,h//2, w//2)\n",
    "\n",
    "        el2 = self.en_block2(max1)    #(64, h//2, w//2)\n",
    "\n",
    "        max2 = nn.MaxPool2d(2)(el2)  #(64, h//4, w//4)\n",
    "\n",
    "        el3 = self.en_block3(max2)    #(128, h//4, w//4)\n",
    "\n",
    "        max3 = nn.MaxPool2d(2)(el3)  #(128, h//8, w//8)\n",
    "\n",
    "\n",
    "        el4 = self.en_block4(max3)    #(256, h//8, w//8)\n",
    "\n",
    "        max4 = nn.MaxPool2d(2)(el4)  #(256, h//16, w//16)\n",
    "\n",
    "        el5 = self.en_block5(max4)  #(512, h//16, w//16)\n",
    "\n",
    "        max5 = nn.MaxPool2d(2)(el5)  #(512, h//32, w//32)\n",
    "\n",
    "        \n",
    "        el6 = self.en_block6(max5)  #(1024, h//32, w//32)\n",
    "\n",
    "\n",
    "        tl5 = self.transpose5(el6)  #(512, h//16, w//16)\n",
    "\n",
    "        cat5 = torch.cat([tl5, el5], 1) #(1024, h//16, h//16 )\n",
    "\n",
    "        d5 =  self.de_block5(cat5)      #(512, h//16, w//16\n",
    "\n",
    "        \n",
    "        tl4 = self.transpose4(d5)       #(256, h//8, w//8)\n",
    "        cat4 = torch.cat([tl4, el4], 1) #(512, h//8, w//8)\n",
    "        d4 =  self.de_block4(cat4)     #(256, h//8, w//8)\n",
    "        \n",
    "        tl3 = self.transpose3(d4)        #(128, h//4, w//4)\n",
    "        cat3 = torch.cat([tl3, el3], 1)  #(256, h//4, w//4)\n",
    "        d3 =  self.de_block3(cat3)        #(128, h//4, w//4)\n",
    "        \n",
    "        \n",
    "        tl2 = self.transpose2(d3)          #(64, h//2, w//2)\n",
    "        cat2 = torch.cat([tl2, el2], 1)   #(128, h//2, w//2)\n",
    "        d2 =  self.de_block2(cat2)         #(64, h//2, w//2)\n",
    "        \n",
    "        tl1 = self.transpose1(d2)          #(32, h, w)\n",
    "        cat1 = torch.cat([tl1, el1], 1) #(64, h, w)\n",
    "        d1 =  self.de_block1(cat1)        #(32, h, w)\n",
    "        output = torch.sigmoid(self.out_conv(d1)) \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = promise(sli_path,192,mode = 'train', booli = False)\n",
    "dataset_test = promise(sli_path,192,mode = 'test',  booli = False)\n",
    "dataset_val = promise(sli_path,192,mode = 'val',  booli = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_train, 32, shuffle = True)\n",
    "dataloadert = torch.utils.data.DataLoader(dataset_test, 32, shuffle = True)\n",
    "dataloaderv = torch.utils.data.DataLoader(dataset_val, 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76ef79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Unet(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d3b66c",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736912f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(mask, class_label = [0,1,2]):\n",
    "    one_hot_list = []\n",
    "    for label in class_label:\n",
    "        mask_bool = mask[:,0,:,:] == label\n",
    "        one_hot_list.append(mask_bool.to(torch.float32))\n",
    "    one_hot_tensor = torch.stack(one_hot_list,1)\n",
    "    return one_hot_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_dice(inputs, target):\n",
    "    cect = ce(inputs, target[:,0,:,:])\n",
    "    dice = dice_multi_loss(inputs, target)\n",
    "    return cect + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(inputs, target):\n",
    "    smooth = 1e-8\n",
    "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
    "    union = target.sum() + inputs.sum() + smooth\n",
    "\n",
    "    return 1 - (intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e14758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_multi_loss(inputs, target, class_label = [0,1,2]):\n",
    "    one_hot_target = one_hot(target)\n",
    "    dice_sum = 0\n",
    "    for label in class_label:\n",
    "        \n",
    "        dice = dice_loss(inputs[:,label,:,:], one_hot_target[:,label,:,:])\n",
    "        dice_sum+= dice\n",
    "    avg = dice_sum / len(class_label)\n",
    "    return avg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(inputs, target):\n",
    "    smooth = 1e-8\n",
    "    #in_flat = inputs.contiguous().view(-1)\n",
    "    #tar_flat = target.contiguous().view(-1)\n",
    "\n",
    "    intersection = 2.0 * ((target * inputs).sum()) + smooth\n",
    "    union = target.sum() + inputs.sum() + smooth\n",
    "\n",
    "    return  (intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_multi_metric(inputs, target, class_label = [0,1,2]):\n",
    "    one_hot_target = one_hot(target)\n",
    "    dice_sum = 0\n",
    "    for label in class_label:\n",
    "        \n",
    "        dice = dice_metric(inputs[:,label,:,:], one_hot_target[:,label,:,:])\n",
    "        dice_sum+= dice\n",
    "    avg = dice_sum / len(class_label)\n",
    "    return avg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a81c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_multi_metric3(inputs, target, class_label = [1,2]):\n",
    "    predict_label = torch.argmax(inputs, 1)\n",
    "    one_hot_target = one_hot(target)\n",
    "    dice_sum = 0\n",
    "    lis = []\n",
    "    for label in class_label:\n",
    "        inp = (predict_label==label).to(torch.float32)\n",
    "        target = one_hot_target[:,label,:,:]\n",
    "\n",
    "        dice_l = dice_metric(inp, target)\n",
    "        lis.append(dice_l)\n",
    "        \n",
    "   \n",
    "    return lis[0], lis[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, label):\n",
    "    smooth = 1e-8\n",
    "  \n",
    "    output[output>0.8] =1.0\n",
    "    correct = (output == label)\n",
    "    out = correct.sum((1,2,3))\n",
    "    o = (smooth + out)/(torch.sum(label[0,0,...]) + smooth)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f19a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_dice_loss(inputs, target):\n",
    "    inputs = inputs.to(device)\n",
    "    target = inputs.to(device)\n",
    "\n",
    "    dicescore = dice_coef_loss(inputs, target)\n",
    "    bcescore = nn.BCELoss()\n",
    "    bceloss = dice_coef_loss(inputs, target)\n",
    "\n",
    "    return bceloss + dicescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if  torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_step(model, dataload_train, dataload_validation, loss = dice_loss,\n",
    "               epochs = 100,\n",
    "               lr = 0.001,\n",
    "              best = 0.86):\n",
    "\n",
    "    epochs = epochs\n",
    "    model.to(device)\n",
    "    Loss = loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    hist_loss_per_epoch = []\n",
    "    hist_val_per_epoch = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        hist_val_loss_per_batch = []\n",
    "        hist_loss_per_batch = []\n",
    "        hist_dicemean_val_per_batch = []\n",
    "        hist_dicel1_val_per_batch = []\n",
    "        hist_dicel2_val_per_batch = []\n",
    "\n",
    "        acc_val_item = []\n",
    "\n",
    "\n",
    "\n",
    "        for batch, data in enumerate(dataload_train, 1): # dataload return a dict {'image': tensor, 'seg': tensor}\n",
    "            image = data['image'].to(device)\n",
    "            segment = data['seg'].to(device)\n",
    "            \n",
    "            segment_hat = model(image)\n",
    "\n",
    "            loss = Loss(segment_hat, segment) + bc(segment_hat[:,0,...], segment[:,0,...])\n",
    "                      \n",
    "            hist_loss_per_batch.append(loss.item())\n",
    "              \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "       \n",
    "        mean_loss = sum(hist_loss_per_batch)/batch\n",
    "        print(f'Loss in epoch{epoch} is :', mean_loss)\n",
    "        hist_loss_per_epoch.append(mean_loss)\n",
    "        hist_all_metric = []\n",
    "        for batch_val, data_val in enumerate(dataload_validation, 1):\n",
    "            \n",
    "            imaget = data_val['image'].to(device)\n",
    "            segment_t = data_val['seg'].to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                segment_hat_t = model(imaget)\n",
    "                \n",
    "                val_loss = Loss(segment_hat_t,segment_t)\n",
    "                dice_val= dice_metric(segment_hat_t,segment_t)\n",
    "                dice_val1,dice_val2 = dice_multi_metric3(segment_hat_t,segment_t)\n",
    "                \n",
    "                \n",
    "                hist_val_loss_per_batch.append(val_loss.item())\n",
    "                hist_dicemean_val_per_batch.append(dice_val.item())\n",
    "                hist_dicel1_val_per_batch.append(dice_val1.item())\n",
    "                hist_dicel2_val_per_batch.append(dice_val2.item())\n",
    "\n",
    "                \n",
    "                \n",
    "        mean_val_loss = sum(hist_val_loss_per_batch)/batch_val\n",
    "        mean_dice_val = sum(hist_dicemean_val_per_batch)/batch_val\n",
    "        mean_dice_val_l1 = sum(hist_dicel1_val_per_batch)/batch_val\n",
    "\n",
    "        mean_dice_val_l2 = sum(hist_dicel2_val_per_batch)/batch_val\n",
    "\n",
    "        hist_val_per_epoch.append([mean_val_loss,mean_dice_val])\n",
    "        \n",
    "        print(f'dice_val in epoch{epoch} is :', mean_dice_val)\n",
    "        print(f'l1_val in epoch{epoch} is :', mean_dice_val_l1)\n",
    "        print(f'l2_val in epoch{epoch} is :', mean_dice_val_l2)\n",
    "        print('------------------------------------------')\n",
    "        if mean_dice_val > best:\n",
    "            \n",
    "            torch.save({\"epoch\" : epoch, \n",
    "                        \"model_state\" : model.state_dict(),\n",
    "                       \"optimizer\" : optimizer.state_dict()},\n",
    "                       \n",
    "                       f\"model_{model.__class__.__name__}_epoch_{epoch}_loss_{Loss.__name__}.pt\")\n",
    "\n",
    "        \n",
    "    return hist_loss_per_epoch, hist_val_per_epoch\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1515144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = train_step(m , dataloader, dataloaderv,loss=dice_loss,lr=0.001, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
